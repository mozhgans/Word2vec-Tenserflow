{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDK4plQuYh92czxvBYG0z5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mozhgans/Word2vec-Tenserflow/blob/main/Word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXxBATuq-Ict"
      },
      "source": [
        "Word2Vec\n",
        "\n",
        "here I implement word2vec with very simple example using tensorflow\n",
        "word2vec is vector representation for words with similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSMgulTD-RNB"
      },
      "source": [
        "Collect Data\n",
        "\n",
        "we will use only 10 sentences to create word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfnxLSWh-MQ1"
      },
      "source": [
        "corpus = ['king is a strong man', \n",
        "          'queen is a wise woman', \n",
        "          'boy is a young man',\n",
        "          'girl is a young woman',\n",
        "          'prince is a young king',\n",
        "          'princess is a young queen',\n",
        "          'man is strong', \n",
        "          'woman is pretty',\n",
        "          'prince is a boy will be king',\n",
        "          'princess is a girl will be queen']"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deiqAIGV-d0D"
      },
      "source": [
        "\n",
        "Remove stop words\n",
        "\n",
        "In order for efficiency of creating word vector, we will remove commonly used words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx1su49B-fSS"
      },
      "source": [
        "def remove_stop_words(corpus):\n",
        "    stop_words = ['is', 'a', 'will', 'be']\n",
        "    results = []\n",
        "    for text in corpus:\n",
        "        tmp = text.split(' ')\n",
        "        for stop_word in stop_words:\n",
        "            if stop_word in tmp:\n",
        "                tmp.remove(stop_word)\n",
        "        results.append(\" \".join(tmp))\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxA27kp_-rj6"
      },
      "source": [
        "corpus = remove_stop_words(corpus)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkq3RA2i-uvV"
      },
      "source": [
        "words = []\n",
        "for text in corpus:\n",
        "    for word in text.split(' '):\n",
        "        words.append(word)\n",
        "\n",
        "words = set(words)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ploNBb5-0wp"
      },
      "source": [
        "here we have word set by which we will have word vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sbO7kUL-1iD",
        "outputId": "54e91835-c439-470a-daf0-ec1b6330a41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boy',\n",
              " 'girl',\n",
              " 'king',\n",
              " 'man',\n",
              " 'pretty',\n",
              " 'prince',\n",
              " 'princess',\n",
              " 'queen',\n",
              " 'strong',\n",
              " 'wise',\n",
              " 'woman',\n",
              " 'young'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qMlhO2r--a5"
      },
      "source": [
        "data generation\n",
        "\n",
        "we will generate label for each word using skip gram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GurKes-D_AYi"
      },
      "source": [
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "\n",
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    sentences.append(sentence.split())\n",
        "    \n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTR-a_UA_GV6",
        "outputId": "0f13b88f-64f6-4b8d-ad5f-aac6b6cf47db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import pandas as pd\n",
        "for text in corpus:\n",
        "    print(text)\n",
        "\n",
        "df = pd.DataFrame(data, columns = ['input', 'label'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king strong man\n",
            "queen wise woman\n",
            "boy young man\n",
            "girl young woman\n",
            "prince young king\n",
            "princess young queen\n",
            "man strong\n",
            "woman pretty\n",
            "prince boy king\n",
            "princess girl queen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRM7pJT4_J_m",
        "outputId": "56bb18ec-ad00-4eb5-98d8-c00da0ef1151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>king</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>king</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>strong</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>strong</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>man</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>man</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>queen</td>\n",
              "      <td>wise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>queen</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>wise</td>\n",
              "      <td>queen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>wise</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    input   label\n",
              "0    king  strong\n",
              "1    king     man\n",
              "2  strong    king\n",
              "3  strong     man\n",
              "4     man    king\n",
              "5     man  strong\n",
              "6   queen    wise\n",
              "7   queen   woman\n",
              "8    wise   queen\n",
              "9    wise   woman"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzmjuexU_QWi",
        "outputId": "1ac33a05-1ebc-41ce-dc56-6b6c6a0a11cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjRq4dvm_TJQ",
        "outputId": "ee18d571-ec15-4bf5-80a8-b7da99acc6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "word2int"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boy': 5,\n",
              " 'girl': 8,\n",
              " 'king': 11,\n",
              " 'man': 2,\n",
              " 'pretty': 6,\n",
              " 'prince': 9,\n",
              " 'princess': 3,\n",
              " 'queen': 1,\n",
              " 'strong': 4,\n",
              " 'wise': 0,\n",
              " 'woman': 10,\n",
              " 'young': 7}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3hEUYrx_XDW"
      },
      "source": [
        "Define Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITyPlkLB_8Ss",
        "outputId": "9c354995-9d74-4c58-cbaf-e067191bd13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "print(tf.__version__)\n",
        "ONE_HOT_DIM = len(words)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q38q-R6CBH7P",
        "outputId": "30500ca3-ad70-466e-cd03-ac0a75db836d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!tf_upgrade_v2 \\\n",
        "  --infile models/samples/cookbook/regression/custom_regression.py \\\n",
        "  --outfile /tmp/custom_regression_v2.py"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tf_upgrade_v2\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/tools/compatibility/tf_upgrade_v2_main.py\", line 147, in main\n",
            "    args.input_file, output_file, upgrade)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/tools/compatibility/tf_upgrade_v2_main.py\", line 44, in process_file\n",
            "    upgrader.process_file(in_filename, out_filename)\n",
            "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow_core/tools/compatibility/ast_edits.py\", line 914, in process_file\n",
            "    with open(in_filename, \"r\") as in_file, \\\n",
            "IOError: [Errno 2] No such file or directory: 'models/samples/cookbook/regression/custom_regression.py'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWTI97nBBn30",
        "outputId": "bddbc7f5-0ba4-40cd-ddea-c6c03a6ec5c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "!tf_upgrade_v2 \\\n",
        "    --intree models/samples/cookbook/regression/ \\\n",
        "    --outtree regression_v2/ \\\n",
        "    --reportfile tree_report.txt"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.0 Upgrade Script\n",
            "-----------------------------\n",
            "Converted 0 files\n",
            "Detected 0 issues that require attention\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Make sure to read the detailed log 'tree_report.txt'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1VEdkCTAXSq",
        "outputId": "9326d795-2222-4fe2-c350-024b6e5dc384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PtLWlhu_dkV",
        "outputId": "0187e69c-2dd7-4dbf-cf06-0aff44312f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "ONE_HOT_DIM = len(words)\n",
        "\n",
        "# function to convert numbers to one hot vectors\n",
        "def to_one_hot_encoding(data_point_index):\n",
        "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
        "    one_hot_encoding[data_point_index] = 1\n",
        "    return one_hot_encoding\n",
        "\n",
        "X = [] # input word\n",
        "Y = [] # target word\n",
        "\n",
        "for x, y in zip(df['input'], df['label']):\n",
        "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
        "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
        "\n",
        "# convert them to numpy arrays\n",
        "X_train = np.asarray(X)\n",
        "Y_train = np.asarray(Y)\n",
        "\n",
        "# making placeholders for X_train and Y_train\n",
        "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
        "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
        "\n",
        "# word embedding will be 2 dimension for 2d visualization\n",
        "EMBEDDING_DIM = 2 \n",
        "\n",
        "# hidden layer: which represents word vector eventually\n",
        "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
        "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
        "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
        "\n",
        "\n",
        "\n",
        "# output layer\n",
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
        "b2 = tf.Variable(tf.random_normal([1]))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
        "\n",
        "# loss function: cross entropy\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
        "\n",
        "# training operation\n",
        "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d3acfa6f1d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# making placeholders for X_train and Y_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_HOT_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mONE_HOT_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBF9SscOCAGv"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yEeuvjjB64B",
        "outputId": "3d657350-75b3-42f3-e31f-6e16d26b65db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) \n",
        "\n",
        "iteration = 20000\n",
        "for i in range(iteration):\n",
        "    # input is X_train which is one hot encoded word\n",
        "    # label is Y_train which is one hot encoded neighbor word\n",
        "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
        "    if i % 3000 == 0:\n",
        "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-20eb0c674eaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlXapJc0CH7R"
      },
      "source": [
        "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
        "vectors = sess.run(W1 + b1)\n",
        "print(vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQVE2YkRCLAS"
      },
      "source": [
        "\n",
        "word vector in table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZADunl7CMM2"
      },
      "source": [
        "\n",
        "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
        "w2v_df['word'] = words\n",
        "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
        "w2v_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ME18WFICRrS"
      },
      "source": [
        "word vector in 2d chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuBeLC-nCSh_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
        "    ax.annotate(word, (x1,x2 ))\n",
        "    \n",
        "PADDING = 1.0\n",
        "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
        "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
        "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
        "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
        " \n",
        "plt.xlim(x_axis_min,x_axis_max)\n",
        "plt.ylim(y_axis_min,y_axis_max)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}